{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# To add a new cell, type '# %%'\n","# To add a new markdown cell, type '# %% [markdown]'\n","# %%\n","from lightgbm import train\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from pytest import param\n","import seaborn as sns\n","\n","import lightgbm as lgb\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error\n","from scipy.fftpack import dct\n","from scipy.fftpack import idct\n","\n"]},{"cell_type":"markdown","metadata":{},"source":[" #### -- 모델 준비"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# 원전 내부의 충돌체 정보를 네개의 센서 정보만으로 특정해내기\n","# 데이터 출처 : https://dacon.io/competitions/official/235614/overview/description/\n","train_features = pd.read_csv('D:/Data/KAERI_dataset/train_features.csv')\n","train_target = pd.read_csv('D:/Data/KAERI_dataset/train_target.csv')\n","\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((1050000, 6), (2800, 5))"]},"metadata":{},"execution_count":3}],"source":["train_features.shape, train_target.shape\n","\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id      Time   S1   S2   S3   S4\n","0   0  0.000000  0.0  0.0  0.0  0.0\n","1   0  0.000004  0.0  0.0  0.0  0.0\n","2   0  0.000008  0.0  0.0  0.0  0.0\n","3   0  0.000012  0.0  0.0  0.0  0.0\n","4   0  0.000016  0.0  0.0  0.0  0.0"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Time</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.000004</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.000008</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.000012</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.000016</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":4}],"source":["train_features.head()\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def find_firt_min_amp(data0,min_amp=937.55):\n","    data = data0.copy()\n","    cond_min = (np.abs(data['S1']) > min_amp) | (np.abs(data['S2']) > min_amp) | (np.abs(data['S3']) > min_amp) | (np.abs(data['S4']) > min_amp)\n","    data_active = data[cond_min]\n","    data_active = data_active.drop_duplicates(['id'],keep='first')\n","\n","    return data_active\n",""]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# scipy에서 Discrete Cosine Transform을 사용, 원하는 만큼만 잘라낼 수 있게 함수 설정\n","def fourier_trsf(data,sensor,id=10,cutoff=65):\n","\tcond_id = data['id']==id\n","\twave = data.loc[cond_id,sensor].values\n","\ttime = data.loc[cond_id,'Time']\n","\tfft_wave = dct(wave, type=2,n=time.shape[0])\n","\tfreq = np.fft.fftfreq(wave.size,d=0.000004)\n","\tcw = np.copy(fft_wave)\n","\tcw[cutoff:]=0\n","\tfft_wave_2 = np.real(idct(cw))\n","\t\n","\treturn {\"cw\":cw[:cutoff],\"fft\":fft_wave, \"freq\":freq, \"fft_cutoff\":fft_wave_2, \"time\":time, \"wave\":wave}\n",""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["\n","def find_unique_freq(data0,head=40):\n","    data = data0.copy()\n","    id_list = np.array(data['id'].unique())\n","    set_dict = {}\n","    n = data[data['id']==0].shape[0]\n","    nn = int(n/2)+1\n","\n","    for s in ['S1','S2','S3','S4']:\n","        min_set = set(range(0,nn))\n","        for i in id_list:\n","            fft_wave = fourier_trsf(data=data,sensor=s,id=i)\n","            freq = fft_wave['freq'][0:nn]\n","            amp = fft_wave['fft'][0:nn]\n","            abs_amp = abs(amp)\n","\n","            df_wave = pd.DataFrame([freq,amp,abs_amp]).T\n","            df_wave.columns = ['freq','amp','abs_amp']\n","            set_i = set(df_wave.sort_values(by='abs_amp',ascending=False).head(head).index)\n","\n","            min_set = min_set - set_i\n","\n","        set_dict[s]=min_set\n","    return set_dict\n",""]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# 65번째 까지(0~64) 킵해보자\n","# 일단 feature로 만들어서 넣어주는 함수를 짜자\n","# column이름은 f1_0~f4_65같은 식으로 넣기\n","def fourier_feature(data0,cutoff=65):\n","    data = data0.copy()\n","    id_list = np.array(data['id'].unique())\n","    df_id = pd.DataFrame(id_list,columns=['id'])\n","    df_list = [df_id]\n","\n","    for s in ['S1','S2','S3','S4']:\n","        df_s = []\n","        for i in id_list:\n","            fft_wave = fourier_trsf(data=data,sensor=s,id=i,cutoff=cutoff)\n","            amp = fft_wave['cw']\n","            \n","            df_wave = pd.DataFrame(amp).T\n","            df_wave.columns = [s+'_f'+str(n) for n in range(cutoff)]\n","            df_s.append(df_wave)\n","        df_sensor = pd.concat(df_s,axis=0).reset_index(drop=True)\n","        df_list.append(df_sensor)\n","\n","    df_tot = pd.concat(df_list,axis=1)\n","\n","    return df_tot\n",""]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# 확인 해보니, S3가 먼저 신호를 받은 경우가 한번도 없는 것으로 나온다\n","# 그래서 S3가 항상 고려되지 않은채로 분류 된 것...\n","# 추후에도 S3값이 고려 될 수 있게, 축을 새로 잡아주기\n","def reset_axis(data0,new_axis=('A','B','C','D')):\n","    data = data0.copy()\n","    \n","    # A=(S1+S2+S3+S4)/4, B=(S1+S2-S3-S4)/4, C=(S1-S2-S3+S4)/4, D=(S1-S2+S3-S4)/4\n","    ns1,ns2,ns3,ns4 = data['S1'],data['S2'],data['S3'],data['S4']\n","    data[new_axis[0]] = (ns1+ns2+ns3+ns4)/4\n","    data[new_axis[1]] = (ns1+ns2-ns3-ns4)/4\n","    data[new_axis[2]] = (ns1-ns2-ns3+ns4)/4\n","    data[new_axis[3]] = (ns1-ns2+ns3-ns4)/4\n","    data = data.drop(['Time','S1','S2','S3','S4'],axis=1)\n","    \n","    return data\n",""]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# 앞서 수행했던 데이터 전처리 및 feature engineering을 수행해주는 함수\n","def feature_eng_df(data,cutoff=80):   \n","    cond_0 = (data['S1'] != 0) | (data['S2'] != 0) | (data['S3'] != 0) | (data['S4'] != 0)\n","    data_active = data[cond_0]\n","    data_active = data_active.drop_duplicates(['id'],keep='first')\n","    \n","    new_axis = ('A','B','C','D')\n","    data_new = reset_axis(data,new_axis=new_axis)\n","    cond_new = (data_new['A'] != 0) | (data_new['B'] != 0) | (data_new['C'] != 0) | (data_new['D'] != 0)  \n","    data_active_new = data_new[cond_new]\n","    data_active_new = data_active_new.drop_duplicates(['id'],keep='first')\n","    \n","    data_active = data_active.merge(data_active_new,on='id')\n","    \n","    for s in ['S1','S2','S3','S4']:\n","        min_s = data.groupby(by='id').min()[s]\n","        max_s = data.groupby(by='id').max()[s]\n","        gap_s = max_s - min_s\n","        gap_s = gap_s.reset_index()\n","        gap_s.columns = ['id','gap_'+s]\n","        data_active = data_active.merge(gap_s,on='id')\n","\n","    data_active['Time'] = (data_active['Time']*10**6).astype('int')\n","\n","    data[(data['S2'] != 0)].drop_duplicates(['id'],keep='first')[['id','Time']]\n","\n","    for s in ['S1','S2','S3','S4']:\n","        cond_t = (data[s] != 0)\n","        active_time = data[cond_t].drop_duplicates(['id'],keep='first')[['id','Time']]\n","        active_time['Time'] = (active_time['Time']*10**6).astype('int')\n","        active_time.columns = ['id','active_time_'+s]\n","        data_active = data_active.merge(active_time,on='id')\n","\n","    data_active['R12'] = (data_active['active_time_S1']+data_active['active_time_S2'])/(data_active['active_time_S3']+data_active['active_time_S4'])\n","    data_active['R13'] = (data_active['active_time_S1']+data_active['active_time_S3'])/(data_active['active_time_S2']+data_active['active_time_S4'])\n","    data_active['R14'] = (data_active['active_time_S1']+data_active['active_time_S4'])/(data_active['active_time_S2']+data_active['active_time_S3'])\n","\n","    data_active['RMS_S'] = (data_active['S1']**2+data_active['S2']**2+data_active['S3']**2+data_active['S4']**2)**0.5\n","    data_active['RMS_gap'] = (data_active['gap_S1']**2+data_active['gap_S2']**2+data_active['gap_S3']**2+data_active['gap_S4']**2)**0.5\n","    data_active['RMS_time'] = (data_active['active_time_S1']**2+data_active['active_time_S2']**2+data_active['active_time_S3']**2+data_active['active_time_S4']**2)**0.5\n","    \n","    data_fft = fourier_feature(data,cutoff=cutoff)\n","    data_active = data_active.merge(data_fft,on='id')\n","\n","    return data_active\n","\n",""]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                   0             1              2             3             4\n","id      0.000000e+00  1.000000e+00       2.000000  3.000000e+00  4.000000e+00\n","Time    4.000000e+01  2.000000e+01      16.000000  3.200000e+01  2.000000e+01\n","S1     -4.972607e-08  0.000000e+00      -0.000092  0.000000e+00  3.230998e-07\n","S2     -4.972607e-08 -4.104924e-07       0.000000 -1.783159e-07  0.000000e+00\n","S3      0.000000e+00  0.000000e+00       0.000000  0.000000e+00  0.000000e+00\n","...              ...           ...            ...           ...           ...\n","S4_f75  1.684120e+06 -1.518072e+06  -61321.832785 -5.812756e+05 -9.751388e+05\n","S4_f76  2.884239e+04 -5.615888e+06 -120137.749756 -8.366543e+05  3.916767e+05\n","S4_f77  3.995064e+05 -1.179631e+06   99635.066101  4.095499e+05 -9.707762e+04\n","S4_f78  2.543315e+05  2.940736e+06  100054.862204  9.089064e+05  1.146868e+04\n","S4_f79  4.671553e+05 -5.467193e+06  227935.909372  1.626792e+05  7.479534e+05\n","\n","[344 rows x 5 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>id</th>\n      <td>0.000000e+00</td>\n      <td>1.000000e+00</td>\n      <td>2.000000</td>\n      <td>3.000000e+00</td>\n      <td>4.000000e+00</td>\n    </tr>\n    <tr>\n      <th>Time</th>\n      <td>4.000000e+01</td>\n      <td>2.000000e+01</td>\n      <td>16.000000</td>\n      <td>3.200000e+01</td>\n      <td>2.000000e+01</td>\n    </tr>\n    <tr>\n      <th>S1</th>\n      <td>-4.972607e-08</td>\n      <td>0.000000e+00</td>\n      <td>-0.000092</td>\n      <td>0.000000e+00</td>\n      <td>3.230998e-07</td>\n    </tr>\n    <tr>\n      <th>S2</th>\n      <td>-4.972607e-08</td>\n      <td>-4.104924e-07</td>\n      <td>0.000000</td>\n      <td>-1.783159e-07</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>S3</th>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>0.000000</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>S4_f75</th>\n      <td>1.684120e+06</td>\n      <td>-1.518072e+06</td>\n      <td>-61321.832785</td>\n      <td>-5.812756e+05</td>\n      <td>-9.751388e+05</td>\n    </tr>\n    <tr>\n      <th>S4_f76</th>\n      <td>2.884239e+04</td>\n      <td>-5.615888e+06</td>\n      <td>-120137.749756</td>\n      <td>-8.366543e+05</td>\n      <td>3.916767e+05</td>\n    </tr>\n    <tr>\n      <th>S4_f77</th>\n      <td>3.995064e+05</td>\n      <td>-1.179631e+06</td>\n      <td>99635.066101</td>\n      <td>4.095499e+05</td>\n      <td>-9.707762e+04</td>\n    </tr>\n    <tr>\n      <th>S4_f78</th>\n      <td>2.543315e+05</td>\n      <td>2.940736e+06</td>\n      <td>100054.862204</td>\n      <td>9.089064e+05</td>\n      <td>1.146868e+04</td>\n    </tr>\n    <tr>\n      <th>S4_f79</th>\n      <td>4.671553e+05</td>\n      <td>-5.467193e+06</td>\n      <td>227935.909372</td>\n      <td>1.626792e+05</td>\n      <td>7.479534e+05</td>\n    </tr>\n  </tbody>\n</table>\n<p>344 rows × 5 columns</p>\n</div>"},"metadata":{},"execution_count":11}],"source":["df_features = feature_eng_df(train_features)\n","df_features.head().T\n","\n",""]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["targets = list(train_target.columns)[1:]\n","features = list(df_features.columns)[1:]\n",""]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   id  Time            S1            S2   S3   S4             A             B  \\\n","0   0    40 -4.972607e-08 -4.972607e-08  0.0  0.0 -2.486304e-08 -2.486304e-08   \n","1   1    20  0.000000e+00 -4.104924e-07  0.0  0.0 -1.026231e-07 -1.026231e-07   \n","2   2    16 -9.210808e-05  0.000000e+00  0.0  0.0 -2.302702e-05 -2.302702e-05   \n","3   3    32  0.000000e+00 -1.783159e-07  0.0  0.0 -4.457897e-08 -4.457897e-08   \n","4   4    20  3.230998e-07  0.000000e+00  0.0  0.0  8.077495e-08  8.077495e-08   \n","\n","              C             D  ...        S4_f74        S4_f75        S4_f76  \\\n","0  0.000000e+00  0.000000e+00  ... -6.845378e+05  1.684120e+06  2.884239e+04   \n","1  1.026231e-07  1.026231e-07  ... -5.314059e+05 -1.518072e+06 -5.615888e+06   \n","2 -2.302702e-05 -2.302702e-05  ...  4.349310e+04 -6.132183e+04 -1.201377e+05   \n","3  4.457897e-08  4.457897e-08  ... -4.198138e+05 -5.812756e+05 -8.366543e+05   \n","4  8.077495e-08  8.077495e-08  ... -1.710859e+06 -9.751388e+05  3.916767e+05   \n","\n","         S4_f77        S4_f78        S4_f79      X      Y      M    V  \n","0  3.995064e+05  2.543315e+05  4.671553e+05    0.0 -400.0   50.0  0.4  \n","1 -1.179631e+06  2.940736e+06 -5.467193e+06  400.0    0.0  100.0  1.0  \n","2  9.963507e+04  1.000549e+05  2.279359e+05 -300.0 -200.0   25.0  0.4  \n","3  4.095499e+05  9.089064e+05  1.626792e+05  200.0 -100.0  150.0  0.4  \n","4 -9.707762e+04  1.146868e+04  7.479534e+05 -300.0 -100.0  150.0  0.4  \n","\n","[5 rows x 348 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Time</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>...</th>\n      <th>S4_f74</th>\n      <th>S4_f75</th>\n      <th>S4_f76</th>\n      <th>S4_f77</th>\n      <th>S4_f78</th>\n      <th>S4_f79</th>\n      <th>X</th>\n      <th>Y</th>\n      <th>M</th>\n      <th>V</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>40</td>\n      <td>-4.972607e-08</td>\n      <td>-4.972607e-08</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-2.486304e-08</td>\n      <td>-2.486304e-08</td>\n      <td>0.000000e+00</td>\n      <td>0.000000e+00</td>\n      <td>...</td>\n      <td>-6.845378e+05</td>\n      <td>1.684120e+06</td>\n      <td>2.884239e+04</td>\n      <td>3.995064e+05</td>\n      <td>2.543315e+05</td>\n      <td>4.671553e+05</td>\n      <td>0.0</td>\n      <td>-400.0</td>\n      <td>50.0</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>20</td>\n      <td>0.000000e+00</td>\n      <td>-4.104924e-07</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.026231e-07</td>\n      <td>-1.026231e-07</td>\n      <td>1.026231e-07</td>\n      <td>1.026231e-07</td>\n      <td>...</td>\n      <td>-5.314059e+05</td>\n      <td>-1.518072e+06</td>\n      <td>-5.615888e+06</td>\n      <td>-1.179631e+06</td>\n      <td>2.940736e+06</td>\n      <td>-5.467193e+06</td>\n      <td>400.0</td>\n      <td>0.0</td>\n      <td>100.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>16</td>\n      <td>-9.210808e-05</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-2.302702e-05</td>\n      <td>-2.302702e-05</td>\n      <td>-2.302702e-05</td>\n      <td>-2.302702e-05</td>\n      <td>...</td>\n      <td>4.349310e+04</td>\n      <td>-6.132183e+04</td>\n      <td>-1.201377e+05</td>\n      <td>9.963507e+04</td>\n      <td>1.000549e+05</td>\n      <td>2.279359e+05</td>\n      <td>-300.0</td>\n      <td>-200.0</td>\n      <td>25.0</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>32</td>\n      <td>0.000000e+00</td>\n      <td>-1.783159e-07</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-4.457897e-08</td>\n      <td>-4.457897e-08</td>\n      <td>4.457897e-08</td>\n      <td>4.457897e-08</td>\n      <td>...</td>\n      <td>-4.198138e+05</td>\n      <td>-5.812756e+05</td>\n      <td>-8.366543e+05</td>\n      <td>4.095499e+05</td>\n      <td>9.089064e+05</td>\n      <td>1.626792e+05</td>\n      <td>200.0</td>\n      <td>-100.0</td>\n      <td>150.0</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>20</td>\n      <td>3.230998e-07</td>\n      <td>0.000000e+00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.077495e-08</td>\n      <td>8.077495e-08</td>\n      <td>8.077495e-08</td>\n      <td>8.077495e-08</td>\n      <td>...</td>\n      <td>-1.710859e+06</td>\n      <td>-9.751388e+05</td>\n      <td>3.916767e+05</td>\n      <td>-9.707762e+04</td>\n      <td>1.146868e+04</td>\n      <td>7.479534e+05</td>\n      <td>-300.0</td>\n      <td>-100.0</td>\n      <td>150.0</td>\n      <td>0.4</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 348 columns</p>\n</div>"},"metadata":{},"execution_count":13}],"source":["df = df_features.merge(train_target,on='id')\n","df.head()\n","\n",""]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["((2239, 348), (560, 348), (2800, 348))"]},"metadata":{},"execution_count":14}],"source":["# 데이터를 학습용, 검증용으로 분리\n","df_train, df_val = train_test_split(df[1:],test_size=0.2,train_size=0.8,random_state=2)\n","df_train.shape, df_val.shape, df.shape\n","\n",""]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["y_train = df_train[targets]\n","y_train_xy = df_train[['X','Y']]\n","y_train_mv = df_train[['M','V']]\n","X_train = df_train[features]\n","\n","y_val = df_val[targets]\n","y_val_xy = df_val[['X','Y']]\n","y_val_mv = df_val[['M','V']]\n","X_val = df_val[features]\n","\n",""]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# dacon에서 제공하는 평가 지표 함수. 낮을 수록 좋은 값.\n","def kaeri_metric(y_true, y_pred):    \n","    return 0.5 * E1(y_true, y_pred) + 0.5 * E2(y_true, y_pred)\n","\n","def E1(y_true, y_pred):\n","    _t, _p = np.array(y_true)[:,:2], np.array(y_pred)[:,:2]\n","    return np.mean(np.sum(np.square(_t - _p), axis = 1) / 2e+04)\n","\n","def E2(y_true, y_pred):\n","    _t, _p = np.array(y_true)[:,2:], np.array(y_pred)[:,2:]           \n","    return np.mean(np.sum(np.square((_t - _p) / (_t + 1e-06)), axis = 1))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["id    1399.5\n","X        0.0\n","Y       -5.0\n","M      100.0\n","V        0.6\n","dtype: float64"]},"metadata":{},"execution_count":17}],"source":["train_target.max()\n","train_target.min()\n","train_target.mean()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["LGBM\n {'n_estimators': 100, 'learning_rate': 0.09, 'max_depth': 4, 'num_leaves': 15, 'boosting_type': 'goss', 'random_state': 2}\n"]},{"output_type":"execute_result","data":{"text/plain":["   mae_ratio(v/t)  kaeri_score_train  mae_train  rmse_train  kaeri_score_val  \\\n","0            1.56           0.009579   2.592183    4.675246         0.022102   \n","\n","    mae_val  rmse_val  \n","0  4.055866  8.302376  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mae_ratio(v/t)</th>\n      <th>kaeri_score_train</th>\n      <th>mae_train</th>\n      <th>rmse_train</th>\n      <th>kaeri_score_val</th>\n      <th>mae_val</th>\n      <th>rmse_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.56</td>\n      <td>0.009579</td>\n      <td>2.592183</td>\n      <td>4.675246</td>\n      <td>0.022102</td>\n      <td>4.055866</td>\n      <td>8.302376</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":18}],"source":["params = {}\n","params['n_estimators'] = 100 \n","params['learning_rate'] = 0.09 # 0.1 # 0.15\n","params['max_depth'] = 4\n","params['num_leaves'] = 15 # 5\n","params['boosting_type'] = 'goss'# 'dart'\n","params['random_state'] = 2\n","print('LGBM\\n',params)\n","\n","model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n","\n","model.fit(X_train,y_train)\n","\n","y_train_pred_xgb = model.predict(X_train)\n","y_val_pred_xgb = model.predict(X_val)\n","\n","# 스코어 계산\n","kaeri_score_train = kaeri_metric(y_train,y_train_pred_xgb)\n","mae_train = mean_absolute_error(y_train,y_train_pred_xgb)\n","rmse_train = mean_squared_error(y_train,y_train_pred_xgb)**0.5\n","kaeri_score_val = kaeri_metric(y_val,y_val_pred_xgb)\n","mae_val = mean_absolute_error(y_val,y_val_pred_xgb)\n","rmse_val = mean_squared_error(y_val,y_val_pred_xgb)**0.5\n","\n","score = pd.DataFrame([round(mae_val/mae_train,2),kaeri_score_train,mae_train, rmse_train, kaeri_score_val,mae_val,rmse_val]).T\n","score.columns=['mae_ratio(v/t)','kaeri_score_train', 'mae_train', 'rmse_train', 'kaeri_score_val', 'mae_val', 'rmse_val']\n","\n","score"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["LGBM\n {'n_estimators': 1000, 'learning_rate': 0.1, 'max_depth': 4, 'num_leaves': 5, 'boosting_type': 'dart', 'random_state': 2}\n"]},{"output_type":"execute_result","data":{"text/plain":["   mae_ratio(v/t)  kaeri_score_train  mae_train  rmse_train  kaeri_score_val  \\\n","0            1.35           0.007085   2.567204    4.669485         0.017345   \n","\n","    mae_val  rmse_val  \n","0  3.477992  6.642705  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mae_ratio(v/t)</th>\n      <th>kaeri_score_train</th>\n      <th>mae_train</th>\n      <th>rmse_train</th>\n      <th>kaeri_score_val</th>\n      <th>mae_val</th>\n      <th>rmse_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.35</td>\n      <td>0.007085</td>\n      <td>2.567204</td>\n      <td>4.669485</td>\n      <td>0.017345</td>\n      <td>3.477992</td>\n      <td>6.642705</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":21}],"source":["params = {}\n","params['n_estimators'] = 1000\n","params['learning_rate'] = 0.1 # 0.15\n","params['max_depth'] = 4\n","params['num_leaves'] = 5\n","params['boosting_type'] = 'dart'\n","params['random_state'] = 2\n","print('LGBM\\n',params)\n","\n","model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n","\n","model.fit(X_train,y_train)\n","\n","y_train_pred_xgb = model.predict(X_train)\n","y_val_pred_xgb = model.predict(X_val)\n","\n","# 스코어 계산\n","kaeri_score_train = kaeri_metric(y_train,y_train_pred_xgb)\n","mae_train = mean_absolute_error(y_train,y_train_pred_xgb)\n","rmse_train = mean_squared_error(y_train,y_train_pred_xgb)**0.5\n","kaeri_score_val = kaeri_metric(y_val,y_val_pred_xgb)\n","mae_val = mean_absolute_error(y_val,y_val_pred_xgb)\n","rmse_val = mean_squared_error(y_val,y_val_pred_xgb)**0.5\n","\n","score = pd.DataFrame([round(mae_val/mae_train,2),kaeri_score_train,mae_train, rmse_train, kaeri_score_val,mae_val,rmse_val]).T\n","score.columns=['mae_ratio(v/t)','kaeri_score_train', 'mae_train', 'rmse_train', 'kaeri_score_val', 'mae_val', 'rmse_val']\n","\n","score"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["LGBM\n {'n_estimators': 1000, 'learning_rate': 0.15, 'max_depth': 4, 'num_leaves': 5, 'boosting_type': 'dart', 'random_state': 2}\n"]},{"output_type":"execute_result","data":{"text/plain":["   mae_ratio(v/t)  kaeri_score_train  mae_train  rmse_train  kaeri_score_val  \\\n","0            1.53            0.00382   1.794849    3.378536         0.011853   \n","\n","   mae_val  rmse_val  \n","0  2.74859  5.513833  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mae_ratio(v/t)</th>\n      <th>kaeri_score_train</th>\n      <th>mae_train</th>\n      <th>rmse_train</th>\n      <th>kaeri_score_val</th>\n      <th>mae_val</th>\n      <th>rmse_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.53</td>\n      <td>0.00382</td>\n      <td>1.794849</td>\n      <td>3.378536</td>\n      <td>0.011853</td>\n      <td>2.74859</td>\n      <td>5.513833</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":22}],"source":["params = {}\n","params['n_estimators'] = 1000\n","params['learning_rate'] = 0.15 #0.1\n","params['max_depth'] = 4\n","params['num_leaves'] = 5\n","params['boosting_type'] = 'dart'\n","params['random_state'] = 2\n","print('LGBM\\n',params)\n","\n","model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n","\n","model.fit(X_train,y_train)\n","\n","y_train_pred_xgb = model.predict(X_train)\n","y_val_pred_xgb = model.predict(X_val)\n","\n","# 스코어 계산\n","kaeri_score_train = kaeri_metric(y_train,y_train_pred_xgb)\n","mae_train = mean_absolute_error(y_train,y_train_pred_xgb)\n","rmse_train = mean_squared_error(y_train,y_train_pred_xgb)**0.5\n","kaeri_score_val = kaeri_metric(y_val,y_val_pred_xgb)\n","mae_val = mean_absolute_error(y_val,y_val_pred_xgb)\n","rmse_val = mean_squared_error(y_val,y_val_pred_xgb)**0.5\n","\n","score = pd.DataFrame([round(mae_val/mae_train,2),kaeri_score_train,mae_train, rmse_train, kaeri_score_val,mae_val,rmse_val]).T\n","score.columns=['mae_ratio(v/t)','kaeri_score_train', 'mae_train', 'rmse_train', 'kaeri_score_val', 'mae_val', 'rmse_val']\n","\n","score"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["LGBM\n {'n_estimators': 1000, 'learning_rate': 0.02, 'max_depth': 6, 'num_leaves': 5, 'boosting_type': 'gbdt', 'random_state': 2}\n"]},{"output_type":"execute_result","data":{"text/plain":["   mae_ratio(v/t)  kaeri_score_train  mae_train  rmse_train  kaeri_score_val  \\\n","0            1.45           0.008532   2.551268    4.754366         0.018756   \n","\n","    mae_val  rmse_val  \n","0  3.708665  7.407671  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mae_ratio(v/t)</th>\n      <th>kaeri_score_train</th>\n      <th>mae_train</th>\n      <th>rmse_train</th>\n      <th>kaeri_score_val</th>\n      <th>mae_val</th>\n      <th>rmse_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.45</td>\n      <td>0.008532</td>\n      <td>2.551268</td>\n      <td>4.754366</td>\n      <td>0.018756</td>\n      <td>3.708665</td>\n      <td>7.407671</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":30}],"source":["params = {}\n","params['n_estimators'] = 1000 #100\n","params['learning_rate'] = 0.02 #0.15 #0.1\n","params['max_depth'] = 6\n","params['num_leaves'] = 5 #5\n","params['boosting_type'] = 'gbdt'#'dart' #'goss'\n","params['random_state'] = 2\n","print('LGBM\\n',params)\n","\n","model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n","\n","model.fit(X_train,y_train)\n","\n","y_train_pred_xgb = model.predict(X_train)\n","y_val_pred_xgb = model.predict(X_val)\n","\n","# 스코어 계산\n","kaeri_score_train = kaeri_metric(y_train,y_train_pred_xgb)\n","mae_train = mean_absolute_error(y_train,y_train_pred_xgb)\n","rmse_train = mean_squared_error(y_train,y_train_pred_xgb)**0.5\n","kaeri_score_val = kaeri_metric(y_val,y_val_pred_xgb)\n","mae_val = mean_absolute_error(y_val,y_val_pred_xgb)\n","rmse_val = mean_squared_error(y_val,y_val_pred_xgb)**0.5\n","\n","score = pd.DataFrame([round(mae_val/mae_train,2),kaeri_score_train,mae_train, rmse_train, kaeri_score_val,mae_val,rmse_val]).T\n","score.columns=['mae_ratio(v/t)','kaeri_score_train', 'mae_train', 'rmse_train', 'kaeri_score_val', 'mae_val', 'rmse_val']\n","\n","score"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["LGBM\n {'n_estimators': 1000, 'learning_rate': 0.02, 'max_depth': 6, 'num_leaves': 6, 'boosting_type': 'gbdt', 'random_state': 2}\n"]},{"output_type":"execute_result","data":{"text/plain":["   mae_ratio(v/t)  kaeri_score_train  mae_train  rmse_train  kaeri_score_val  \\\n","0            1.64           0.005663   2.060817    3.922484         0.015297   \n","\n","    mae_val  rmse_val  \n","0  3.375315  7.031755  "],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mae_ratio(v/t)</th>\n      <th>kaeri_score_train</th>\n      <th>mae_train</th>\n      <th>rmse_train</th>\n      <th>kaeri_score_val</th>\n      <th>mae_val</th>\n      <th>rmse_val</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.64</td>\n      <td>0.005663</td>\n      <td>2.060817</td>\n      <td>3.922484</td>\n      <td>0.015297</td>\n      <td>3.375315</td>\n      <td>7.031755</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{},"execution_count":38}],"source":["params = {}\n","params['n_estimators'] = 1000 #100\n","params['learning_rate'] = 0.02 #0.15 #0.1\n","params['max_depth'] = 6\n","params['num_leaves'] = 6 #5\n","params['boosting_type'] = 'gbdt'#'dart' #'goss'\n","params['random_state'] = 2\n","print('LGBM\\n',params)\n","\n","model = MultiOutputRegressor(lgb.LGBMRegressor(**params))\n","\n","model.fit(X_train,y_train)\n","\n","y_train_pred_xgb = model.predict(X_train)\n","y_val_pred_xgb = model.predict(X_val)\n","\n","# 스코어 계산\n","kaeri_score_train = kaeri_metric(y_train,y_train_pred_xgb)\n","mae_train = mean_absolute_error(y_train,y_train_pred_xgb)\n","rmse_train = mean_squared_error(y_train,y_train_pred_xgb)**0.5\n","kaeri_score_val = kaeri_metric(y_val,y_val_pred_xgb)\n","mae_val = mean_absolute_error(y_val,y_val_pred_xgb)\n","rmse_val = mean_squared_error(y_val,y_val_pred_xgb)**0.5\n","\n","score = pd.DataFrame([round(mae_val/mae_train,2),kaeri_score_train,mae_train, rmse_train, kaeri_score_val,mae_val,rmse_val]).T\n","score.columns=['mae_ratio(v/t)','kaeri_score_train', 'mae_train', 'rmse_train', 'kaeri_score_val', 'mae_val', 'rmse_val']\n","\n","score"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}